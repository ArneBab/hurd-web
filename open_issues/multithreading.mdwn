[[!meta copyright="Copyright Â© 2010, 2011, 2012 Free Software Foundation,
Inc."]]

[[!meta license="""[[!toggle id="license" text="GFDL 1.2+"]][[!toggleable
id="license" text="Permission is granted to copy, distribute and/or modify this
document under the terms of the GNU Free Documentation License, Version 1.2 or
any later version published by the Free Software Foundation; with no Invariant
Sections, no Front-Cover Texts, and no Back-Cover Texts.  A copy of the license
is included in the section entitled [[GNU Free Documentation
License|/fdl]]."]]"""]]

[[!tag open_issue_hurd]]

Hurd servers / VFS libraries are multithreaded.


# Implementation

  * well-known threading libraries

      * [[hurd/libthreads]]

      * [[hurd/libpthread]]


# Design

See [[hurd/libports]]: roughly using one thread per
incoming request.  This is not the best approach: it doesn't really make sense
to scale the number of worker threads with the number of incoming requests, but
instead they should be scaled according to the backends' characteristics.

The [[hurd/Critique]] should have some more on this.

[*Event-based Concurrency
Control*](http://soft.vub.ac.be/~tvcutsem/talks/presentations/T37_nobackground.pdf),
Tom Van Cutsem, 2009.


## IRC, freenode, #hurd, 2012-07-08

    <youpi> braunr: about limiting number of threads, IIRC the problem is that
      for some threads, completing their work means triggering some action in
      the server itself, and waiting for it (with, unfortunately, some lock
      held), which never terminates when we can't create new threads any more
    <braunr> youpi: the number of threads should be limited, but not globally
      by libports
    <braunr> pagers should throttle their writeback requests
    <youpi> right


## IRC, freenode, #hurd, 2012-07-16

    <braunr> hm interesting
    <braunr> when many threads are creating to handle requests, they
      automatically create a pool of worker threads by staying around for some
      time
    <braunr> this time is given in the libport call
    <braunr> but the thread always remain
    <braunr> they must be used in turn each time a new requet comes in
    <braunr> ah no :(, they're maintained by the periodic sync :(
    <braunr> hm, still not that, so weird
    <antrik> braunr: yes, that's a known problem: unused threads should go away
      after some time, but that doesn't actually happen
    <antrik> don't remember though whether it's broken for some reason, or
      simply not implemented at all...
    <antrik> (this was already a known issue when thread throttling was
      discussed around 2005...)
    <braunr> antrik: ok
    <braunr> hm threads actually do finish ..
    <braunr> libthreads retain them in a pool for faster allocations
    <braunr> hm, it's worse than i thought
    <braunr> i think the hurd does its job well
    <braunr> the cthreads code never reaps threads
    <braunr> when threads are finished, they just wait until assigned a new
      invocation

    <braunr> i don't understand ports_manage_port_operations_multithread :/
    <braunr> i think i get it
    <braunr> why do people write things in such a complicated way ..
    <braunr> such code is error prone and confuses anyone

    <braunr> i wonder how well nested functions interact with threads when
      sharing variables :/
    <braunr> the simple idea of nested functions hurts my head
    <braunr> do you see my point ? :) variables on the stack automatically
      shared between threads, without the need to explicitely pass them by
      address
    <antrik> braunr: I don't understand. why would variables on the stack be
      shared between threads?...
    <braunr> antrik: one function declares two variables, two nested functions,
      and use these in separate threads
    <braunr> are the local variables still "local"
    <braunr> ?
    <antrik> braunr: I would think so? why wouldn't they? threads have separate
      stacks, right?...
    <antrik> I must admit though that I have no idea how accessing local
      variables from the parent function works at all...
    <braunr> me neither

    <braunr> why don't demuxers get a generic void * like every callback does
      :((
    <antrik> ?
    <braunr> antrik: they get pointers to the input and output messages only
    <antrik> why is this a problem?
    <braunr> ports_manage_port_operations_multithread can be called multiple
      times in the same process
    <braunr> each call must have its own context
    <braunr> currently this is done by using nested functions
    <braunr> also, why demuxers return booleans while mach_msg_server_timeout
      happily ignores them :(
    <braunr> callbacks shouldn't return anything anyway
    <braunr> but then you have a totally meaningless "return 1" in the middle
      of the code
    <braunr> i'd advise not using a single nested function
    <antrik> I don't understand the remark about nested function
    <braunr> they're just horrible extensions
    <braunr> the compiler completely hides what happens behind the scenes, and
      nasty bugs could come out of that
    <braunr> i'll try to rewrite ports_manage_port_operations_multithread
      without them and see if it changes anything
    <braunr> but it's not easy
    <braunr> also, it makes debugging harder :p
    <braunr> i suspect gdb hangs are due to that, since threads directly start
      on a nested function
    <braunr> and if i'm right, they are created on the stack
    <braunr> (which is also horrible for security concerns, but that's another
      story)
    <braunr> (at least the trampolines)
    <antrik> I seriously doubt it will change anything... but feel free to
      prove me wrong :-)
    <braunr> well, i can see really weird things, but it may have nothing to do
      with the fact functions are nested
    <braunr> (i still strongly believe those shouldn't be used at all)


# Alternative approaches:

  * <http://www.concurrencykit.org/>

  * Continuation-passing style

      * [[microkernel/Mach]] internally [[uses
        continuations|microkernel/mach/continuation]], too.

  * [[Erlang-style_parallelism]]

      * [[!wikipedia Actor_model]]; also see overlap with
        {{$capability#wikipedia_object-capability_model}}.

  * [libtcr - Threaded Coroutine Library](http://oss.linbit.com/libtcr/)

  * <http://monkey.org/~provos/libevent/>

---

See also: [[multiprocessing]].
